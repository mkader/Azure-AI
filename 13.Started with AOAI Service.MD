# Get started with Azure OpenAI Service

![](img/13/1.studio-portal.png)
* Generative AI models power ChatGPT's ability to produce new content, such as text, code, and images, based on a NL prompts. Many generative AI models are a subset of DL algorithms. These algorithms support various workloads across vision, speech, language, decision, search, and more.

# Access Azure OpenAI Service
* Building a generative AI solution with Azure OpenAI is to provision an Azure OpenAI resource. Azure OpenAI Service is currently in limited access. Users need to apply for service access at https://aka.ms/oai/access.

* Create an Azure OpenAI Service resource in the Azure portal or CLI

# Use Azure OpenAI Studio
* Azure OpenAI Studio provides access to model management, deployment, experimentation, customization, and learning resources.

* Access the Azure OpenAI Studio through the Azure portal after creating a resource, or at https://oai.azure.com by logging in with your Azure OpenAI resource instance.

![](img/13/2.openai-portal-navigation.png)
* Create new deployment. 

* Once in the studio, your next steps include:
    1. Choosing a base model.
    2. Deploying a base model.
    3. Testing the model. An easy way to do this is in one of the studio playgrounds.
    4. Experimenting with prompts and parameters to see their effect on completions, or the generated output.

# Explore types of generative AI models
* Building with Azure OpenAI, choose a base model and deploy it. 
* Family |	Description |	Base models within the Family
    1. GPT-4 | Models that generate NL and code. | gpt-4, gpt-4-32k
    2. GPT-3 | Models that can understand and generate NL. | text-davinci-003, text-curie-001, text-babbage-001, text-ada-001, gpt-35-turbo
    3. Codex | Models that can understand and generate code, including translating NL to code. | code-davinci-002, code-cushman-001
    4. Embeddings | Embeddings are further broken down into three families of models for different functionalities: similarity, text search, and code search. | See the list https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models?portal=true
 
* Choosing a model
    1. The models within the family differ by speed, cost, and how well they complete tasks. 
    2. In general, models with the name davinci are stronger than models with the name curie, babbage, and ada, but may be slower.
    3. Pricing is determiend by tokens and by model type. [Learn more about the latest pricing here](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)

![](img/13/3.studio-models.png)
* Azure OpenAI Studio navigation

# Deploy generative AI models
* first need to deploy a model to make API calls to receive completions to prompts. When you create a new deployment, you need to indicate which base model to deploy. You can only deploy one instance of each model. There are several ways you can deploy your base model.
  ![](img/13/4.studio-deployment.png)
  1. Deploy using Azure OpenAI Studio - create a new deployment by selecting a model name from the menu.
  2. Deploy using Azure CLI
  3. Deploy using the REST API

# Use prompts to get completions from models
* Once the model is deployed, you can test how it completes prompts. 
* A prompt is the text portion of a request that is sent to the deployed model's completions endpoint. 
* Responses are referred to as completions, which can come in form of text, code, or other formats.
* Prompt types
* Task type | Prompt example | Completion example
    1. Classifying content | Tweet: I enjoyed the trip.
    Sentiment: |	Positive
    2. Generating new content |	List ways of traveling | 1. Bike
    2. Car ...
    3. Holding a conversation |	A friendly AI assistant |	See examples
    4. Transformation (translation and symbol conversion) |	English: Hello
    French: |	bonjour
    5. Summarizing content | Provide a summary of the content
    {text} | The content shares methods of machine learning.
    6. Picking up where you left off | One way to grow tomatoes | is to plant seeds.
    7. Giving factual responses |	How many moons does Earth have? |	One

* Completion quality
    1. The way a prompt is engineered. 
    2. The model parameters
    3. The data the model is trained on, which can be adapted through model fine-tuning with customization

# Test models in Azure OpenAI Studio's playgrounds

![](img/13/5.azure-openai-completions-playground.png)
* Completions playground - allows you to make calls to your deployed models through a text-in, text-out interface and to adjust parameters. 
* parameters - adjust to change the performance of your model:
    1. Temperature: Controls randomness. Lowering the temperature means that the model produces more repetitive and deterministic responses. Increasing the temperature results in more unexpected or creative responses. Try adjusting temperature or Top P but not both.
    2. Max length (tokens): Set a limit on the number of tokens per model response. The API supports a maximum of 4000 tokens shared between the prompt (including system message, examples, message history, and user query) and the model's response. One token is roughly four characters for typical English text.
    3. Stop sequences: Make responses stop at a desired point, such as the end of a sentence or list. Specify up to four sequences where the model will stop generating further tokens in a response. The returned text won't contain the stop sequence.
    4. Top probabilities (Top P): Similar to temperature, this controls randomness but uses a different method. Lowering Top P narrows the model’s token selection to likelier tokens. Increasing Top P lets the model choose from tokens with both high and low likelihood. Try adjusting temperature or Top P but not both.
    5. Frequency penalty: Reduce the chance of repeating a token proportionally based on how often it has appeared in the text so far. This decreases the likelihood of repeating the exact same text in a response.
    6. Presence penalty: Reduce the chance of repeating any token that has appeared in the text at all so far. This increases the likelihood of introducing new topics in a response.
    7. Pre-response text: Insert text after the user’s input and before the model’s response. This can help prepare the model for a response.
    8. Post-response text: Insert text after the model’s generated response to encourage further user input, as when modeling a conversation.

* Chat playground - is based on a conversation-in, message-out interface.
    ![](img/13/6.azure-openai-chat-playground.png)
    1. Few-shot examples - refers to providing a few of examples to help the model learn what it needs to do.
    2. Assistant setup, you can provide few-shot examples of what the user input may be, and what the assistant response should be.
    3. Parameters
        1. Max response: Set a limit on the number of tokens per model response. supports a maximum of 4000 tokens.
        2. Top P: Similar to temperature.
        3. Past messages included: Select the number of past messages to include in each new API request. Including past messages helps give the model context for new user queries. Setting this number to 10 will include five user queries and five system responses.
        4. Current token count: set a max response token limit, keep an eye make sure the conversation-in doesn't exceed the max response token count.

# Exercise - Get started with Azure OpenAI Service
* https://microsoftlearning.github.io/mslearn-openai/Instructions/Labs/01-get-started-azure-openai.html

1. Create an Azure OpenAI resource

2. Deploy a model through Azure OpenAI (AI) Studio portal
    1. Deployments -> create new deployment -> Model name: text-davinci-003 | Deployment name: text-davinci
    2. the Davinci model from the GPT-3 family of text generation models. text-davinci-003 is a good general model for summarizing and generating NL.

3. Explore a model in the Completions playground
    1. experiment with your deployed models without needing to develop your own client application.
    2. Completions -> Deployments : text-davinci | Examples : Summarize an article (abstractive). | summary text display | the the number of tokens detected in the text. Tokens are the basic units of a prompt (words or word-parts in the text) -> Generate -> retrieve a response (summary of the text).
    3. Regenerate (icon) to resubmit the prompt -> the response may vary from the original one
    4. Under the summarized response, add a new line : How has AI advanced? -> Generate -> review the response. 
    5. Azure OpenAI Service provides REST API access.
   
* ![](img/13/7.classify_text.PNG)
4. Use a model to classify text - the generative models in Azure OpenAI can support a range of different types of task. Let’s explore a different example; text classification.
    1. Completions -> Deployments : text-davinci | Examples : Classify text -> Generate -> predict an appropriate category for the article
    2. It then provides the text for the news article (prefixed by News article: or Headeline 1:) and ends with Classified category:

* ![](img/13/8.auto_generated.PNG)
5. Explore prompts and parameters - Up until now, you’ve based your prompts on examples that are provided in Azure OpenAI Studio. Let’s try something different.
    1. Replace all of the text in the prompt area with the following text:
    ``` mark
      You are a teacher creating a test for your students.
      
      Write three multiple choice questions based on the following text.
      
      Most computer vision solutions are based on machine learning models that can be applied to visual input from cameras, videos, or images.
      
      - Image classification involves training a machine learning model to classify images based on their contents. For example, in a traffic monitoring solution you might use an image classification model to classify images based on the type of vehicle they contain, such as taxis, buses, cyclists, and so on.
      
      - Object detection machine learning models are trained to classify individual objects within an image, and identify their location with a bounding box. For example, a traffic monitoring solution might use object detection to identify the location of different classes of vehicle.
      
      - Semantic segmentation is an advanced machine learning technique in which individual pixels in the image are classified according to the object to which they belong. For example, a traffic monitoring solution might overlay traffic images with “mask” layers to highlight different vehicles using specific colors.
    ```
    2. In the Parameters pane ->  Temperature: 0 | Max length (tokens): 500 | Pre-response text: Auto-generated questions. Validate before using in a test:
    3. Generate -> review the results, which should consist of the value in the pre-response text parameter followed by multiple-choice questions.
    4. Observe the following about the prompt and parameters you used: The parameters include Temperature, which controls the degree to which response generation includes an element of randomness. The value of 0 used in your submission minimizes randomness, resulting in stable, predictable responses.
    5. Change the Temperature : 0.9 -> the questions are more likely to contain inaccuracies than the ones in the previously generated response.

6. Explore code-generation - generate computer code rather than NL text, and some models have been optimized for that task.
      1. Create new deployment -> Select a model code-davinci-002 | deployment name : code-davinci -> Completions -> Deployments : code-davinci | Examples : Natural language to SQL (The intention is for the model to complete the SELECT statement to create a query) -> Generate.
      2.  Natural language to Python -> Generate python code
       
* ![](img/13/9.chat.PNG)
7. Explore models for chat - Provide a wide variety of NL responses in a conversational scenario. Select the gpt-35-turbo model. Select Chat Playground
    1. Assistant setup -> System message : The system is an AI teacher that helps people learn about AI
    2. Add an example :
        ``` mark
        User: What are different types of artificial intelligence?
        
        Assistant: There are three main types of artificial intelligence: Narrow or Weak AI (such as virtual assistants like Siri or Alexa, image recognition software, and spam filters), General or Strong AI (AI designed to be as intelligent as a human being. This type of AI does not currently exist and is purely theoretical), and Artificial Superintelligence (AI that is more intelligent than any human being and can perform tasks that are beyond human comprehension. This type of AI is also purely theoretical and has not yet been developed).
        ```
    3. Note: Add an examples are used to provide the model with examples of the types of responses that are expected. The model will attempt to reflect the tone and style of the examples in its own responses.
    4. Save changes -> start a new session -> enter user messaget: What is artificial intelligence? -> Send -> view the response -> context from the previous interaction is retained (so the model understands that “it” refers to artificial intelligence).

# Quiz 
1. What Azure OpenAI base model can you deploy to access the capabilities of ChatGPT?
  * [ ] text-davinci-003
  * [x] gpt-35-turbo
  * [ ] text-embedding-ada-002 (Version 2)

2. Which parameter could you adjust to change the randomness or creativeness of the completions returned?
  * [x] Temperature
  * [ ] Frequency penalty
  * [ ] Stop sequence

3. Which Azure OpenAI Studio playground is able to support conversation-in, message-out scenarios?
  * [ ] Completions
  * [x] Chat
  * [ ] Bot
