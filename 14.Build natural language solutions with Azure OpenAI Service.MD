# Build natural language solutions with Azure OpenAI Service
* Choose and deploy a model
  1. Text or Generative Pre-trained Transformer (GPT) - Models that understand and generate NL and some code. These models are best at general tasks, conversations, and chat formats.
  2. Code - Code models are built on top of GPT models, and trained on millions of lines of code. These models can understand and generate code, including interpreting comments or natural language to generate code.
  3. Embeddings - These models can understand and use embeddings, which are a special format of data that can be used by machine learning models and algorithms.

* Available endpoints
  1. Completion - model takes an input prompt, and generates one or more predicted completions
  2. ChatCompletion - model takes input in the form of a chat conversation (where roles are specified with the message they send), and the next chat completion is generated
  3. Embeddings - model takes input and returns a vector representation of that input

* Use Azure OpenAI REST API
  1. AOAI offers a REST API for interacting and generating responses that developers can use to add AI functionality to their applications. YOUR_ENDPOINT_NAME (base endpoint, like sample.openai.azure.com) | YOUR_API_KEY | YOUR_DEPLOYMENT_NAME 
  2. Completions - which generates the completion of your prompt.
``` mark
    curl https://YOUR_ENDPOINT_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/completions?api-version=2022-12-01\
      -H "Content-Type: application/json" \
      -H "api-key: YOUR_API_KEY" \
      -d "{
      \"prompt\": \"Your favorite Shakespeare is\",
      \"max_tokens\": 5
    }"

The JSON response:
    {
        "id": "<id>",
        "object": "text_completion",
        "created": 1679001781,
        "model": "text-davinci-003",
        "choices": [
            {
                "text": "Macbeth",
                "index": 0,
                "logprobs": null,
                "finish_reason": "stop"
            }
        ]
    }
```
      1. choices[].text - The completion response within. 
      2. finish_reason, which in this example is stop. 
      3. Other possibilities for finish_reason include length, which means it used up the max_tokens specified in the request, or content_filter, which means the system detected harmful content was generated from the prompt. If harmful content is included in the prompt, the API request returns an error.

  3. Chat completions - chat/completions generates a completion to your prompt, but works best when that prompt is a chat exchange.
``` mark
    curl https://YOUR_ENDPOINT_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/chat/completions?api-version=2023-03-15-preview \
      -H "Content-Type: application/json" \
      -H "api-key: YOUR_API_KEY" \
      -d '{"messages":[{"role": "system", "content": "You are a helpful assistant, teaching people about AI."},
    {"role": "user", "content": "Does Azure OpenAI support multiple languages?"},
    {"role": "assistant", "content": "Yes, Azure OpenAI supports several languages, and can translate between them."},
    {"role": "user", "content": "Do other Azure Cognitive Services support translation too?"}]}'

The JSON response:
    {
        "id": "chatcmpl-6v7mkQj980V1yBec6ETrKPRqFjNw9",
        "object": "chat.completion",
        "created": 1679001781,
        "model": "gpt-35-turbo",
        "usage": {
            "prompt_tokens": 95,
            "completion_tokens": 84,
            "total_tokens": 179
        },
        "choices": [
            {
                "message":
                    {
                        "role": "assistant",
                        "content": "Yes, other Azure Cognitive Services also support translation. ..."
                    },
                "finish_reason": "stop",
                "index": 0
            }
        ]
    }
```
  4. Both completion endpoints allow for specifying other optional input parameters, such as temperature, max_tokens and more.
  5. Embeddings - are helpful for specific formats that are easily consumed by ML models. To generate embeddings from the input text, POST a request to the embeddings endpoint.
``` mark  
    curl https://YOUR_ENDPOINT_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/embeddings?api-version=2022-12-01 \
      -H "Content-Type: application/json" \
      -H "api-key: YOUR_API_KEY" \
      -d "{\"input\": \"The food was delicious and the waiter...\"}"

When generating embeddings, be sure to use a model in AOAI meant for embeddings. Those models start with text-embedding or text-similarity, depending on what functionality you're looking for.

The JSON response:
  {
    "object": "list",
    "data": [
      {
        "object": "embedding",
        "embedding": [
          0.0172990688066482523,
          -0.0291879814639389515,
          ....
          0.0134544348834753042,
        ],
        "index": 0
      }
    ],
    "model": "text-embedding-ada:002"
  }
